<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Docker部署MongoDB分片+副本集集群（实战）</title>
    <url>/2020/12/10/datebases/mongodb/</url>
    <content><![CDATA[<p>在实际生产环境中，我们往往需要对数据进行分片，以满足业务的需求，本文将介绍如何使用Docker部署MongoDB分片+副本集集群。</p>
<span id="more"></span>
<hr>
<p>本次实践部署mongodb集群，<br>主要借鉴于该博客（<a href="https://blog.csdn.net/weixin_42104521/article/details/103731266%EF%BC%89%E3%80%82">https://blog.csdn.net/weixin_42104521/article/details/103731266）。</a></p>
<h1 id="一、原理简析"><a href="#一、原理简析" class="headerlink" title="一、原理简析"></a>一、原理简析</h1><p>Mongodb一共有三种集群搭建的方式：<br>Replica Set（副本集）、<br>Sharding（切片）<br>Master-Slaver（主从）</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mongoDB目前已不推荐使用主从模式，取而代之的是副本集模式。副本集其实一种互为主从的关系，可理解为主主。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;副本集：指将数据复制，多份保存，不同服务器保存同一份数据，在出现故障时自动切换。对应的是数据冗余、备份、镜像、读写分离、高可用性等关键词；<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分片：则指为处理大量数据，将数据分开存储，不同服务器保存不同的数据，它们的数据总和即为整个数据集。追求的是高性能。</p>
<h2 id="本实验模拟的MongoDB集群分以下几个层次或角色"><a href="#本实验模拟的MongoDB集群分以下几个层次或角色" class="headerlink" title="本实验模拟的MongoDB集群分以下几个层次或角色"></a>本实验模拟的MongoDB集群分以下几个层次或角色</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mongos层：请求的入口，是router的角色，相当于监听，负责将请求分发到对应的存储数据的shard上，多副本冗余</span><br><span class="line"></span><br><span class="line">config server层：记录了mongos中使用到的元数据，自动向mongos同步最新的集群配置，多副本冗余</span><br><span class="line"></span><br><span class="line">shard主节点层：将数据分片，数据库拆分，并将其分散在不同的机器上，原理是将整个数据集合切块</span><br><span class="line">块分散到各个shard中，每个shard只负责总数据的一部分，通过一个均衡器来对各个shard均衡，多副本冗余</span><br><span class="line"></span><br><span class="line">shard副本层：是shard的备份，多副本冗余</span><br><span class="line"></span><br><span class="line">shard仲裁层：用于仲裁，不存储数据，使用最小的资源，需要基数个仲裁角色，且不能放在同一设备上</span><br></pre></td></tr></table></figure>

<h2 id="主机角色端口规划"><a href="#主机角色端口规划" class="headerlink" title="主机角色端口规划"></a>主机角色端口规划</h2><p>本次实践在自建虚拟机进行部署，三台主机，各分配一个IP地址，IP地址如下：</p>
<table>
<thead>
<tr>
<th>服务器</th>
<th>192.168.1.32</th>
<th>192.168.1.33</th>
<th>192.168.1.35</th>
</tr>
</thead>
<tbody><tr>
<td>服务端口</td>
<td>mongos:27017</td>
<td>mongos:27017</td>
<td>mongos:27017</td>
</tr>
<tr>
<td>服务端口</td>
<td>config server:9001</td>
<td>config server:9001</td>
<td>config server:9001</td>
</tr>
<tr>
<td>服务端口</td>
<td>shard1 主节点:9005</td>
<td>shard1 副节点:9005</td>
<td>shard1 仲裁节点:9005</td>
</tr>
<tr>
<td>服务端口</td>
<td>shard2 仲裁节点:9006</td>
<td>shard2 主节点:9006</td>
<td>shard2 副节点:9006</td>
</tr>
<tr>
<td>服务端口</td>
<td>shard3 副节点:9007</td>
<td>shard3 仲裁节点:9007</td>
<td>shard3 主节点:9007</td>
</tr>
</tbody></table>
<p>可以看到每台主机上有1个mongos、1个config server、3个分片，三台主机的相同分片之间构成了主、副和仲裁三个角色。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">应用请求mongos来操作mongodb的增删改查</span><br><span class="line">配置服务器存储数据库元信息，并且和mongos做同步</span><br><span class="line">数据最终存入在shard（分片）上</span><br><span class="line">为了防止数据丢失同步在副本集中存储了一份</span><br><span class="line">仲裁在数据存储到分片的时候决定存储到哪个节点</span><br></pre></td></tr></table></figure>

<h1 id="二、部署配置服务器"><a href="#二、部署配置服务器" class="headerlink" title="二、部署配置服务器"></a>二、部署配置服务器</h1><h2 id="创建挂载目录、配置文件"><a href="#创建挂载目录、配置文件" class="headerlink" title="创建挂载目录、配置文件"></a>创建挂载目录、配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /data/mongod/configdata/configsvr -p   //三台主机都执行</span><br><span class="line"><span class="built_in">mkdir</span> /data/mongod/conf/&#123;configsvr,keyfile&#125; -p   // keyfile在开启用户认证时需要</span><br></pre></td></tr></table></figure>
<h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim /data/mongod/conf/configsvr/mongod.conf</span></span><br><span class="line">net:</span><br><span class="line">  bindIpAll: <span class="literal">true</span></span><br><span class="line">replication:</span><br><span class="line">  replSetName: rs_configsvr <span class="comment"># 副本集名称，相同副本须使用同一个副本集名称</span></span><br><span class="line">  </span><br><span class="line">sharding: </span><br><span class="line">   clusterRole: configsvr   <span class="comment"># 定义为mongo配置服务器</span></span><br></pre></td></tr></table></figure>

<h2 id="启动configsvr"><a href="#启动configsvr" class="headerlink" title="启动configsvr"></a>启动configsvr</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 三台主机均执行此操作</span></span><br><span class="line">docker run -d -p 9001:27019 --name configsvr \</span><br><span class="line">  --entrypoint <span class="string">&quot;mongod&quot;</span> \</span><br><span class="line">  -v /data/mongod/configdata/configsvr:/data/configdb \</span><br><span class="line">  -v /data/mongod/conf/keyfile:/data/keyfile \</span><br><span class="line">  -v /data/mongod/conf/configsvr:/data/conf \</span><br><span class="line">  mongo:4.0.21 -f /data/conf/mongod.conf</span><br></pre></td></tr></table></figure>
<p>备注：如果docker ps 没有刚才创建的容器名称，可以使用docker logs &lt;容器id&gt;查看docker 日志</p>
<h2 id="初始化配置服务复制集"><a href="#初始化配置服务复制集" class="headerlink" title="初始化配置服务复制集"></a>初始化配置服务复制集</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入容器中，创建的三个配置服务中随便一个</span></span><br><span class="line">docker <span class="built_in">exec</span> -it configsvr bash</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 登录mongo</span></span><br><span class="line">mongo --host 192.168.1.32 --port 9001</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 初始化</span></span><br><span class="line">use admin</span><br><span class="line">rs.initiate(&#123;</span><br><span class="line">    _id: <span class="string">&quot;rs_configsvr&quot;</span>,</span><br><span class="line">    configsvr: <span class="literal">true</span>,</span><br><span class="line">    members: [</span><br><span class="line">            &#123; _id : 0, host : <span class="string">&quot;192.168.1.32:9001&quot;</span> &#125;,</span><br><span class="line">            &#123; _id : 1, host : <span class="string">&quot;192.168.1.33:9001&quot;</span> &#125;,</span><br><span class="line">            &#123; _id : 2, host : <span class="string">&quot;192.168.1.35:9001&quot;</span> &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">rs.status()   //查看状态</span><br></pre></td></tr></table></figure>
<h1 id="三、创建分片副本集"><a href="#三、创建分片副本集" class="headerlink" title="三、创建分片副本集"></a>三、创建分片副本集</h1><h2 id="创建分片副本集配置文件、挂载文件"><a href="#创建分片副本集配置文件、挂载文件" class="headerlink" title="创建分片副本集配置文件、挂载文件"></a>创建分片副本集配置文件、挂载文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 创建配置文件、数据目录</span></span><br><span class="line"><span class="built_in">mkdir</span> /data/mongod/shard1/&#123;<span class="built_in">log</span>,db&#125; -p</span><br><span class="line"><span class="built_in">mkdir</span> /data/mongod/shard2/&#123;<span class="built_in">log</span>,db&#125; -p</span><br><span class="line"><span class="built_in">mkdir</span> /data/mongod/shard3/&#123;<span class="built_in">log</span>,db&#125; -p</span><br><span class="line"><span class="built_in">chmod</span> -R 777 /data/mongod/shard1</span><br><span class="line"><span class="built_in">chmod</span> -R 777 /data/mongod/shard2</span><br><span class="line"><span class="built_in">chmod</span> -R 777 /data/mongod/shard3</span><br><span class="line"><span class="built_in">mkdir</span> -p /data/mongod/conf/&#123;shard1,shard2,shard3&#125;  </span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">## 三台主机均创建三个配置文件，shard分片名不同即可</span></span><br><span class="line"><span class="comment">#所有用到的文件夹和文件必须在创建的时候给权限，包括重新创建，也需要重新给权限，并且文件夹要提前创建好</span></span><br><span class="line"><span class="comment"># vim /data/mongod/conf/&#123;shard1,shard2,shard3&#125;/mongod.conf   //添加如下配置信息，分片服务名称不一致即可</span></span><br><span class="line">storage:</span><br><span class="line">  dbPath: /home/mongod/db <span class="comment">#分片数据库路径</span></span><br><span class="line">  journal:</span><br><span class="line">    enabled: <span class="literal">true</span></span><br><span class="line">  directoryPerDB: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">systemLog:</span><br><span class="line">  destination: file</span><br><span class="line">  logAppend: <span class="literal">true</span></span><br><span class="line">  path: /home/mongod/log/mongod.log <span class="comment"># 分片日志</span></span><br><span class="line"></span><br><span class="line">net:</span><br><span class="line">  bindIpAll: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">setParameter:</span><br><span class="line">  enableLocalhostAuthBypass: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">replication:</span><br><span class="line">  replSetName: rs_shardsvr1  <span class="comment"># 分片服务名称</span></span><br><span class="line"> </span><br><span class="line">sharding: </span><br><span class="line">   clusterRole: shardsvr     <span class="comment"># 配置为分片服务</span></span><br></pre></td></tr></table></figure>
<p>注意事项：<br>1、需要提前建立需要的文件夹。并赋予权限（chmod -R 750 文件夹）。<br>2、三个分片服务器建立在三个位置，（docker代码 -v 参数即为实际建立需要的文件夹），需要注意对应创建分片配置文件，文件内容一致。<br>3、注意配置文件中的数据库文件报错路径以及日志文件路径，按需更改。<br>4、分片服务端口需要映射 27018</p>
<h2 id="shard1-分片"><a href="#shard1-分片" class="headerlink" title="shard1 分片"></a>shard1 分片</h2><h3 id="1、mongod分片部署"><a href="#1、mongod分片部署" class="headerlink" title="1、mongod分片部署"></a>1、mongod分片部署</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 三台主机（192.168.1.32、33、35）执行如下启动命令</span></span><br><span class="line">docker run --name shardsvr1 -d -p 9005:27018 \</span><br><span class="line">  --entrypoint <span class="string">&quot;mongod&quot;</span> \</span><br><span class="line">  -v /data/mongod/shard1:/home/mongod \</span><br><span class="line">  -v /data/mongod/conf/keyfile/:/data/keyfile/ \</span><br><span class="line">  -v /data/mongod/conf/shard1/:/data/conf/ \</span><br><span class="line">  mongo:4.0.21 -f /data/conf/mongod.conf</span><br></pre></td></tr></table></figure>

<h3 id="2、初始化分片服务器"><a href="#2、初始化分片服务器" class="headerlink" title="2、初始化分片服务器"></a>2、初始化分片服务器</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 登录进容器中，任意一台</span></span><br><span class="line">docker <span class="built_in">exec</span> -it shardsvr1 bash</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 登录分片服务器</span></span><br><span class="line"><span class="comment"># 192.168.1.32 主分片节点</span></span><br><span class="line"><span class="comment"># 192.168.1.33 副分片节点</span></span><br><span class="line"><span class="comment"># 192.168.1.35 仲裁分片节点，arbiterOnly:true 表示为仲裁节点</span></span><br><span class="line"></span><br><span class="line">mongo --host 192.168.1.32 --port 9005</span><br><span class="line">use admin</span><br><span class="line">rs.initiate(</span><br><span class="line">    &#123;</span><br><span class="line">        _id : <span class="string">&quot;rs_shardsvr1&quot;</span>,</span><br><span class="line">        members: [</span><br><span class="line">            &#123; _id : 0, host : <span class="string">&quot;192.168.1.32:9005&quot;</span>,priority:5 &#125;,</span><br><span class="line">            &#123; _id : 1, host : <span class="string">&quot;192.168.1.33:9005&quot;</span>,priority:3 &#125;,</span><br><span class="line">            &#123; _id : 2, host : <span class="string">&quot;192.168.1.35:9005&quot;</span>,arbiterOnly:<span class="literal">true</span> &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#rs.status() 查看状态</span></span><br></pre></td></tr></table></figure>

<h2 id="shard2-分片"><a href="#shard2-分片" class="headerlink" title="shard2 分片"></a>shard2 分片</h2><h3 id="1、mongod分片部署-1"><a href="#1、mongod分片部署-1" class="headerlink" title="1、mongod分片部署"></a>1、mongod分片部署</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 三台主机（192.168.1.32、33、35）执行如下启动命令</span></span><br><span class="line">docker run --name shardsvr2 -d -p 9006:27018 \</span><br><span class="line">  --entrypoint <span class="string">&quot;mongod&quot;</span> \</span><br><span class="line">  -v /data/mongod/shard2:/home/mongod \</span><br><span class="line">  -v /data/mongod/conf/keyfile/:/data/keyfile/ \</span><br><span class="line">  -v /data/mongod/conf/shard2/:/data/conf/ \</span><br><span class="line">  mongo:4.0.21 -f /data/conf/mongod.conf</span><br></pre></td></tr></table></figure>
<h3 id="2、初始化分片服务器-1"><a href="#2、初始化分片服务器-1" class="headerlink" title="2、初始化分片服务器"></a>2、初始化分片服务器</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 登录进容器中,尽量在主节点执行，否则会报错</span></span><br><span class="line">docker <span class="built_in">exec</span> -it shardsvr2 bash</span><br><span class="line"></span><br><span class="line"><span class="comment">#登录分片服务器</span></span><br><span class="line"><span class="comment"># 192.168.1.32 仲裁分片节点</span></span><br><span class="line"><span class="comment"># 192.168.1.33 主分片节点</span></span><br><span class="line"><span class="comment"># 192.168.1.35 副分片节点</span></span><br><span class="line"></span><br><span class="line">mongo --host 192.168.1.33 --port 9006</span><br><span class="line">use admin</span><br><span class="line">rs.initiate(</span><br><span class="line">    &#123;</span><br><span class="line">        _id : <span class="string">&quot;rs_shardsvr2&quot;</span>,</span><br><span class="line">        members: [</span><br><span class="line">            &#123; _id : 0, host : <span class="string">&quot;192.168.1.32:9006&quot;</span>,arbiterOnly:<span class="literal">true</span> &#125;,</span><br><span class="line">            &#123; _id : 1, host : <span class="string">&quot;192.168.1.33:9006&quot;</span>,priority:5 &#125;,</span><br><span class="line">            &#123; _id : 2, host : <span class="string">&quot;192.168.1.35:9006&quot;</span>,priority:3 &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#rs.status() 查看状态</span></span><br></pre></td></tr></table></figure>

<h2 id="shard3-分片"><a href="#shard3-分片" class="headerlink" title="shard3 分片"></a>shard3 分片</h2><h3 id="1、mongod分片部署-2"><a href="#1、mongod分片部署-2" class="headerlink" title="1、mongod分片部署"></a>1、mongod分片部署</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 三台主机（192.168.1.32、33、35）执行如下启动命令</span></span><br><span class="line">docker run --name shardsvr3 -d -p 9007:27018 \</span><br><span class="line">  --entrypoint <span class="string">&quot;mongod&quot;</span> \</span><br><span class="line">  -v /data/mongod/shard3:/home/mongod \</span><br><span class="line">  -v /data/mongod/conf/keyfile/:/data/keyfile/ \</span><br><span class="line">  -v /data/mongod/conf/shard3/:/data/conf/ \</span><br><span class="line">  mongo:4.0.21 -f /data/conf/mongod.conf</span><br></pre></td></tr></table></figure>
<h3 id="2、初始化分片服务器-2"><a href="#2、初始化分片服务器-2" class="headerlink" title="2、初始化分片服务器"></a>2、初始化分片服务器</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 登录进容器中,任意节点</span></span><br><span class="line">docker <span class="built_in">exec</span> -it shardsvr3 bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 登录分片服务器</span></span><br><span class="line"><span class="comment"># 192.168.1.32 副分片节点</span></span><br><span class="line"><span class="comment"># 192.168.1.33 仲裁分片节点</span></span><br><span class="line"><span class="comment"># 192.168.1.35 主分片节点</span></span><br><span class="line"></span><br><span class="line">mongo --host 192.168.1.35 --port 9007    // 尽量在主节点执行，否则可能会出现报错</span><br><span class="line">use admin</span><br><span class="line">rs.initiate(</span><br><span class="line">    &#123;</span><br><span class="line">        _id : <span class="string">&quot;rs_shardsvr3&quot;</span>,</span><br><span class="line">        members: [</span><br><span class="line">            &#123; _id : 0, host : <span class="string">&quot;192.168.1.32:9007&quot;</span>,priority:3 &#125;,</span><br><span class="line">            &#123; _id : 1, host : <span class="string">&quot;192.168.1.33:9007&quot;</span>,arbiterOnly:<span class="literal">true</span> &#125;,</span><br><span class="line">            &#123; _id : 2, host : <span class="string">&quot;192.168.1.35:9007&quot;</span>,priority:5 &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#rs.status() 查看状态</span></span><br></pre></td></tr></table></figure>

<h1 id="四，创建mongos，连接mongos到分片集群"><a href="#四，创建mongos，连接mongos到分片集群" class="headerlink" title="四，创建mongos，连接mongos到分片集群"></a>四，创建mongos，连接mongos到分片集群</h1><h2 id="创建mongos配置文件"><a href="#创建mongos配置文件" class="headerlink" title="创建mongos配置文件"></a>创建mongos配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /data/mongod/conf/mongos -p   //三台主机都执行</span><br><span class="line"></span><br><span class="line">vim /data/mongod/conf/mongos/mongod.conf</span><br><span class="line"><span class="comment">## 配置文件</span></span><br><span class="line">net:</span><br><span class="line">  bindIpAll: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">sharding: </span><br><span class="line">   configDB: rs_configsvr/192.168.1.32:9001,192.168.1.33:9001,192.168.1.35:9001   <span class="comment"># 定义为mongos配置服务器</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="mongos-部署"><a href="#mongos-部署" class="headerlink" title="mongos 部署"></a>mongos 部署</h2><h3 id="1、分片路由部署-三台均执行相同操作"><a href="#1、分片路由部署-三台均执行相同操作" class="headerlink" title="1、分片路由部署,三台均执行相同操作"></a>1、分片路由部署,三台均执行相同操作</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name mongos -d \</span><br><span class="line">  -p 27017:27017 \</span><br><span class="line">  --entrypoint <span class="string">&quot;mongos&quot;</span> \</span><br><span class="line">  -v /data/mongod/conf/keyfile/:/data/keyfile/ \</span><br><span class="line">  -v /data/mongod/conf/mongos/:/data/conf/ \</span><br><span class="line">  mongo:4.0.21 -f /data/conf/mongod.conf</span><br></pre></td></tr></table></figure>
<p>备注：<br>rs_configsvr&#x2F;192.168.1.32:9001,192.168.1.33:9001,192.168.1.35:9001: 配置服务名称&#x2F;配置服务端口（多个用逗号分隔）</p>
<h3 id="2、初始化mongos"><a href="#2、初始化mongos" class="headerlink" title="2、初始化mongos"></a>2、初始化mongos</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入mongos 容器中</span></span><br><span class="line">docker <span class="built_in">exec</span> -it mongos bash</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 连接mongos</span></span><br><span class="line">mongo --host 127.0.0.1 --port 27017</span><br><span class="line">use admin</span><br><span class="line"><span class="comment"># 添加分片服务器</span></span><br><span class="line">sh.addShard(<span class="string">&quot;rs_shardsvr1/192.168.1.32:9005,192.168.1.33:9005,192.168.1.35:9005&quot;</span>)</span><br><span class="line">sh.addShard(<span class="string">&quot;rs_shardsvr2/192.168.1.32:9006,192.168.1.33:9006,192.168.1.35:9006&quot;</span>)</span><br><span class="line">sh.addShard(<span class="string">&quot;rs_shardsvr3/192.168.1.32:9007,192.168.1.33:9007,192.168.1.35:9007&quot;</span>)</span><br><span class="line"></span><br><span class="line">sh.status() //查看状态</span><br></pre></td></tr></table></figure>

<h3 id="开启分片功能"><a href="#开启分片功能" class="headerlink" title="开启分片功能"></a>开启分片功能</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## db和collection开启分片功能</span></span><br><span class="line">虽然数据库采用分片集群的方式部署，但如果db和collection不启用分片的话（默认是不启用的），数据不会分片存储，此时如果向集群中导入一个db，会将整个db随机存储到任意一个分片中，而不是拆分存储到多个分片。</span><br><span class="line">db启用分片：</span><br><span class="line">sh.enableSharding(<span class="string">&quot;库名&quot;</span>)</span><br><span class="line">sh.enableSharding(<span class="string">&quot;&lt;database&gt;&quot;</span>)</span><br><span class="line">将上述命令中的“”换成实际的db名。</span><br><span class="line"></span><br><span class="line">collection启用分片：</span><br><span class="line">sh.shardCollection(<span class="string">&quot;库名.集合名&quot;</span>,&#123;<span class="string">&quot;key&quot;</span>:1&#125;)</span><br><span class="line">sh.shardCollection(<span class="string">&quot;&lt;database&gt;.&lt;collection&gt;&quot;</span>, &#123; &lt;shard key&gt; : <span class="string">&quot;hashed&quot;</span> &#125; )</span><br><span class="line">上述命令中的“&lt; database &gt;.&lt; collection &gt;”为实际的db名和collection名；“&#123; &lt; shard key &gt; : “hashed” &#125;”为片键的集合。</span><br></pre></td></tr></table></figure>

<h1 id="五，测试使用"><a href="#五，测试使用" class="headerlink" title="五，测试使用"></a>五，测试使用</h1><h2 id="测试使用"><a href="#测试使用" class="headerlink" title="测试使用"></a>测试使用</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 任意一节点操作</span></span><br><span class="line"><span class="comment"># 进入mongos 容器中</span></span><br><span class="line">docker <span class="built_in">exec</span> -it mongos bash</span><br><span class="line"><span class="comment"># 连接mongos</span></span><br><span class="line">mongo --host 127.0.0.1 --port 27017</span><br><span class="line">use admin</span><br><span class="line"></span><br><span class="line"><span class="comment">#  testdb1开启分片功能</span></span><br><span class="line">db.runCommand( &#123; enablesharding  : <span class="string">&quot;testdb1&quot;</span>&#125;);</span><br><span class="line">db.runCommand( &#123; shardcollection : <span class="string">&quot;testdb1.tab1&quot;</span>,key : &#123;<span class="built_in">id</span>: 1&#125; &#125; )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加数据 </span></span><br><span class="line">use testdb1;</span><br><span class="line"><span class="keyword">for</span>(var i=1;i&lt;=20000;i++) db.tab1.save(&#123;<span class="built_in">id</span>:i,<span class="string">&quot;test1&quot;</span>:<span class="string">&quot;testval1&quot;</span>&#125;);</span><br><span class="line"></span><br><span class="line">db.tab1.stats();</span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用testdb1库</span></span><br><span class="line"><span class="comment"># 循环插入数据到testdb1库的tab1集合中的键id中</span></span><br><span class="line"><span class="comment"># 该库对应的该集合对应的该键被设置成了分片</span></span><br><span class="line"><span class="comment"># 查看分片情况</span></span><br></pre></td></tr></table></figure>

<p>分别在三个主机上操作配置库、插入测试数据、查看测试数据<br>验证了副本同步，最后的显示结果看到 “sharded” : true 表示分片也是成功的</p>
<h1 id="六、开启登录认证"><a href="#六、开启登录认证" class="headerlink" title="六、开启登录认证"></a>六、开启登录认证</h1><h2 id="设置数据库账号"><a href="#设置数据库账号" class="headerlink" title="设置数据库账号"></a>设置数据库账号</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">在任意mongos节点操作</span><br><span class="line"><span class="comment"># 进入mongos 容器中</span></span><br><span class="line">docker <span class="built_in">exec</span> -it mongos bash</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 连接mongos</span></span><br><span class="line">mongo --host 127.0.0.1 --port 27017</span><br><span class="line">mongos&gt; use admin</span><br><span class="line">switched to db admin    </span><br><span class="line">mongos&gt; show collections</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">添加两个管理员账号,一个系统管理员:system 一个数据库管理员:administrator</span><br><span class="line">＃先添加系统管理员账号,用来管理用户</span><br><span class="line">mongos&gt; db.createUser(&#123;user:<span class="string">&quot;system&quot;</span>,<span class="built_in">pwd</span>:<span class="string">&quot;123456&quot;</span>,roles:[&#123;role:<span class="string">&quot;root&quot;</span>,db:<span class="string">&quot;admin&quot;</span>&#125;]&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加数据库管理员,用来管理所有数据库</span></span><br><span class="line">mongos&gt; db.createUser(&#123;user:<span class="string">&#x27;administrator&#x27;</span>, <span class="built_in">pwd</span>:<span class="string">&#x27;123456&#x27;</span>, roles:[&#123; role: </span><br><span class="line">mongos&gt; db.auth(<span class="string">&#x27;administrator&#x27;</span>,<span class="string">&#x27;123456&#x27;</span>)    //添加管理员用户认证,认证之后才能管理所有数据库   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 退出，用刚才创建的账号进行登录</span></span><br><span class="line"> mongo 192.168.1.33:27017 -u system -p 123456 --authenticationDatabase admin</span><br><span class="line"> mongo 192.168.1.35:27017 -u administrator -p 123456  --authenticationDatabase admin</span><br></pre></td></tr></table></figure>

<h2 id="开启登录验证"><a href="#开启登录验证" class="headerlink" title="开启登录验证"></a>开启登录验证</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /data/mongod/conf/keyfile -p     //三台主机都执行</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在192.168.1.32节点服务器上操作</span></span><br><span class="line"><span class="built_in">cd</span> /data/mongod/conf/keyfile           //切换到指定目录</span><br><span class="line">openssl rand -<span class="built_in">base64</span> 756 &gt; key.file    //创建一个 keyfile(使用 openssl 生成 756 位 <span class="built_in">base64</span> 加密的字符串)   </span><br><span class="line"><span class="built_in">chmod</span> 600 ./key.file </span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制文件到其他主机</span></span><br><span class="line">scp ./key.file root@192.168.1.33:/data/mongod/conf/keyfile</span><br><span class="line">scp ./key.file root@192.168.1.33:/data/mongod/conf/keyfile</span><br></pre></td></tr></table></figure>
<h2 id="设置配置文件"><a href="#设置配置文件" class="headerlink" title="设置配置文件"></a>设置配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">使用访问控制强制重新启动复制集的每个成员</span><br><span class="line"><span class="comment"># 依次在每台机器上的mongod（注意是所有的mongod不是mongos）的配置文件中加入下面一段配置。如我在192.168.1.32上的config server，shard1，shard2，shard3都加入下面的配置文件</span></span><br><span class="line">security:</span><br><span class="line">  keyFile: /data/keyfile/key.file</span><br><span class="line">  authorization: enabled</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 依次在每台机器上的mongos配置文件中加入下面一段配置</span></span><br><span class="line">security:</span><br><span class="line">  keyFile: /data/keyfile/key.file</span><br></pre></td></tr></table></figure>
<h2 id="重启集群"><a href="#重启集群" class="headerlink" title="重启集群"></a>重启集群</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在三台主机执行如下命令</span></span><br><span class="line">docker ps  |grep mongo |awk -F <span class="string">&quot; &quot;</span> <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> |xargs -r docker restart</span><br></pre></td></tr></table></figure>
<h1 id=""><a href="#" class="headerlink" title=""></a></h1>]]></content>
      <categories>
        <category>数据库</category>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>华为云鲲鹏服务器测试使用-JDK基础镜像构建</title>
    <url>/2021/02/26/docker/jdk-docker/</url>
    <content><![CDATA[<p>近期的大数据项目需要使用ARM环境的服务器；为啥选择华为云呢，因为华为云鲲鹏服务器，具备多核高并发特点，非常适合AI、大数据、HPC、云手机&#x2F;云游戏等场景，满足了我们的需求，所以选择了华为云鲲鹏服务器（支持国产）。</p>
<span id="more"></span>

<hr>
<h1 id="制作JDK基础镜像"><a href="#制作JDK基础镜像" class="headerlink" title="制作JDK基础镜像"></a>制作JDK基础镜像</h1><h2 id="下载jdk软件"><a href="#下载jdk软件" class="headerlink" title="下载jdk软件"></a>下载jdk软件</h2><p>官网地址：<a href="https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html">https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html</a><br><img src="/images/article_image/docker_jdk8_1.png" alt="Alt"><br>本次选择的版本是ARM64版的软件包（jdk-8u271-linux-aarch64.tar.gz）<br>注意：下载可能需要注册账号</p>
<h2 id="下载alpine镜像"><a href="#下载alpine镜像" class="headerlink" title="下载alpine镜像"></a>下载alpine镜像</h2><p>下载apline基础镜像，在dokcer hub上查找适合的镜像即可；需要注意的是，jdk在alpine中运行需要安装glibc，故本次选择的版本：cyphernode&#x2F;alpine-glibc-base:arm64-v3.11.0_2.29-0</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">dokcer pull cyphernode/alpine-glibc-<span class="keyword">base</span>:arm64-v3<span class="number">.11</span><span class="number">.0</span>_2<span class="number">.29</span><span class="number">-0</span></span><br></pre></td></tr></table></figure>

<h2 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#1.指定基础镜像，并且必须是第一条指令</span></span><br><span class="line">FROM cyphernode/alpine-glibc-base:arm64-v3.11.0_2.29-0</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.指明该镜像的作者和其电子邮件</span></span><br><span class="line">MAINTAINER lshcc@163.com</span><br><span class="line"></span><br><span class="line"><span class="comment">#3.设置时间</span></span><br><span class="line">RUN <span class="built_in">ln</span> -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; <span class="built_in">echo</span> <span class="string">&#x27;Asia/Shanghai&#x27;</span> &gt;/etc/timezone</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.将一些安装包复制到镜像中，语法：ADD/COPY &lt;src&gt;... &lt;dest&gt;</span></span><br><span class="line"><span class="comment">## ADD与COPY的区别：ADD复制并解压，COPY仅复制</span></span><br><span class="line">ADD jdk-8u271-linux-aarch64.tar.gz /usr/local/</span><br><span class="line"></span><br><span class="line"><span class="comment">#5.配置环境变量</span></span><br><span class="line">ENV JAVA_HOME=/usr/local/jdk1.8.0_271</span><br><span class="line">ENV JRE_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span>/jre</span><br><span class="line">ENV CLASS_PATH=.:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar:<span class="variable">$JRE_HOME</span>/lib</span><br><span class="line">ENV PATH=<span class="variable">$PATH</span>:<span class="variable">$&#123;JAVA_HOME&#125;</span>/bin:<span class="variable">$JRE_HOME</span>/bin</span><br></pre></td></tr></table></figure>
<h2 id="运行Dockerfile"><a href="#运行Dockerfile" class="headerlink" title="运行Dockerfile"></a>运行Dockerfile</h2><p>新建目录，将Dockerfile和JDK软件包放在同一目录下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@test-0002 pkg]# <span class="built_in">ls</span></span><br><span class="line">Dockerfile  jdk-8u271-linux-aarch64.tar.gz</span><br><span class="line">[root@test-0002 pkg]#</span><br></pre></td></tr></table></figure>
<p>构建JDK基础镜像</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 镜像名称自定义</span></span><br><span class="line">docker build -t jdk8-arm64:v1 .</span><br></pre></td></tr></table></figure>

<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>运行docker镜像，查看java版本<br><img src="/images/article_image/docker_jdk8_2.png" alt="Alt"></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows11系统部署Dify-AI应用开发</title>
    <url>/2025/03/26/AIagent/dify_deployment/</url>
    <content><![CDATA[<h1 id="什么是-Dify-？"><a href="#什么是-Dify-？" class="headerlink" title="什么是 Dify ？"></a>什么是 Dify ？</h1><p>Dify 是一款开源的大语言模型(LLM) 应用开发平台。它融合了后端即服务（Backend as Service）和 LLMOps 的理念，使开发者可以快速搭建生产级的生成式 AI 应用。</p>
<span id="more"></span>
<hr>
<p>由于 Dify 内置了构建 LLM 应用所需的关键技术栈，包括对数百个模型的支持、直观的 Prompt 编排界面、高质量的 RAG 引擎、稳健的 Agent 框架、灵活的流程编排，并同时提供了一套易用的界面和 API。这为开发者节省了许多重复造轮子的时间，使其可以专注在创新和业务需求上。</p>
<p>下面我们开始本地部署Dify</p>
<p><strong>前提条件（官方建议配置）</strong><br>安装 Dify 之前, 请确保你的机器已满足最低安装要求：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CPU &gt;= 2 Core</span><br><span class="line">RAM &gt;= 4 GiB</span><br></pre></td></tr></table></figure>

<h1 id="Windows11-安装Docker和WSL"><a href="#Windows11-安装Docker和WSL" class="headerlink" title="Windows11 安装Docker和WSL"></a>Windows11 安装Docker和WSL</h1><h2 id="安装wsl"><a href="#安装wsl" class="headerlink" title="安装wsl"></a>安装wsl</h2><p>进入cmd或者powershell执行wsl –update，一般下载比较慢，可以从github (<a href="https://github.com/microsoft/WSL/releases%EF%BC%89%E4%B8%8B%E8%BD%BD%EF%BC%8C%E5%A6%82%E4%B8%8B%E5%9B%BE%E6%89%80%E7%A4%BA%EF%BC%8C%E7%84%B6%E5%90%8E%E5%AE%89%E8%A3%85%E5%8D%B3%E5%8F%AF">https://github.com/microsoft/WSL/releases）下载，如下图所示，然后安装即可</a><br><img src="/images/article_image/dify_Deployment_2.png" alt="Alt"></p>
<h2 id="安装Docker-Desktop"><a href="#安装Docker-Desktop" class="headerlink" title="安装Docker Desktop"></a>安装Docker Desktop</h2><p>进入Docker的官方网站<a href="https://www.docker.com,点击下载amd64版本,如图1所示.然后安装即可./">https://www.docker.com，点击下载AMD64版本，如图1所示。然后安装即可。</a><br><img src="/images/article_image/dify_Deployment_3.png" alt="Alt"></p>
<h1 id="安装Dify"><a href="#安装Dify" class="headerlink" title="安装Dify"></a>安装Dify</h1><h2 id="克隆-Dify-代码仓库"><a href="#克隆-Dify-代码仓库" class="headerlink" title="克隆 Dify 代码仓库"></a>克隆 Dify 代码仓库</h2><p>克隆 Dify 源代码至本地环境。我下载是最新的1.1.3<br><code>git clone https://github.com/langgenius/dify.git --branch 1.1.3 </code></p>
<p><em><strong>如果本地没有安装git，可以直接到github下载压缩包到本地再解压</strong></em></p>
<h2 id="启动-Dify"><a href="#启动-Dify" class="headerlink" title="启动 Dify"></a>启动 Dify</h2><h3 id="进入-Dify-源代码的-Docker-目录"><a href="#进入-Dify-源代码的-Docker-目录" class="headerlink" title="进入 Dify 源代码的 Docker 目录"></a>进入 Dify 源代码的 Docker 目录</h3><p><strong>你自己解压的路径</strong><br><code>cd D:\Software\dify-1.1.3\docker</code></p>
<h3 id="复制环境配置文件"><a href="#复制环境配置文件" class="headerlink" title="复制环境配置文件"></a>复制环境配置文件</h3><p><code>cp .env.example .env</code></p>
<p><em><strong>（填坑）注意</strong></em>：windows环境部署，需要更改.env文件的换行格式，可通过vscode打开，否则部署后，在访问localhost\install页面时会出现了internal server error报错，并且无法出现注册页面。.env文件更改（LF改为CRLF），保存文件即可，如下图所示：<br><img src="/images/article_image/dify_Deployment_4.png" alt="Alt"></p>
<h3 id="部署Dify容器"><a href="#部署Dify容器" class="headerlink" title="部署Dify容器"></a>部署Dify容器</h3><ul>
<li>打开docker desktop界面，添加国内镜像加速（推荐，否则下载会失败），添加后重启docker，如下图所示：<br><img src="/images/article_image/dify_Deployment_5.png" alt="Alt"><br><img src="/images/article_image/dify_Deployment_6.png" alt="Alt"></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;registry-mirror&quot;: [</span><br><span class="line">    &quot;https://registry.cn-shenzhen.aliyuncs.com&quot;</span><br><span class="line">  ]</span><br></pre></td></tr></table></figure>

<ul>
<li>根据你系统上的 Docker Compose 版本，选择合适的命令来启动容器。你可以通过 $ docker compose version 命令检查版本，详细说明请参考 Docker 官方文档：<br>我安装的版本是 Docker Compose V2，所以使用以下命令：</li>
</ul>
<p><code>docker compose up -d</code><br>运行命令后，你应该会看到类似以下的输出，显示所有容器的状态：<br><img src="/images/article_image/dify_Deployment_7.png" alt="Alt"></p>
<p>最后检查是否所有容器都正常运行：<br><code>docker compose ps</code><br><img src="/images/article_image/dify_Deployment_8.png" alt="Alt"></p>
<h3 id="访问-Dify"><a href="#访问-Dify" class="headerlink" title="访问 Dify"></a>访问 Dify</h3><p>你可以先前往管理员初始化页面，设置管理员账户：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 本地环境</span><br><span class="line">http://localhost/install</span><br><span class="line"></span><br><span class="line"># 服务器环境</span><br><span class="line">http://your_server_ip/install</span><br></pre></td></tr></table></figure>

<h3 id="docker-compose-停止或者启动dify项目"><a href="#docker-compose-停止或者启动dify项目" class="headerlink" title="docker compose 停止或者启动dify项目"></a>docker compose 停止或者启动dify项目</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker compose stop</span><br><span class="line">docker compose start</span><br></pre></td></tr></table></figure>
<p><img src="/images/article_image/dify_Deployment_9.png" alt="Alt"><br><img src="/images/article_image/dify_Deployment_10.png" alt="Alt"></p>
]]></content>
      <categories>
        <category>Dify</category>
      </categories>
      <tags>
        <tag>Dify</tag>
      </tags>
  </entry>
  <entry>
    <title>etcd数据备份与恢复</title>
    <url>/2021/02/28/kubernetes/etcd_backup/</url>
    <content><![CDATA[<p>对 Etcd 数据进行备份及恢复，Etcd官方也提供了备份的文档，你有兴趣可以阅读一下。这里总结了一些实际操作，以便你后续可以借鉴并进行手动的备份和恢复。命令行里面的一些证书路径以及 endpoint 地址需要根据自己的集群参数进行更改</p>
<span id="more"></span>

<hr>
<h1 id="数据备份"><a href="#数据备份" class="headerlink" title="数据备份"></a><a href="#%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD" title="数据备份"></a>数据备份</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \</span><br><span class="line">--cacert=/etc/kubernetes/pki/etcd/ca.crt \</span><br><span class="line">--key=/etc/kubernetes/pki/etcd/peer.key \</span><br><span class="line">--cert=/etc/kubernetes/pki/etcd/peer.crt \</span><br><span class="line">snapshot save ./new.snapshot.db</span><br></pre></td></tr></table></figure>

<h1 id="查看-etcd-集群的节点"><a href="#查看-etcd-集群的节点" class="headerlink" title="查看 etcd 集群的节点"></a><a href="#%E6%9F%A5%E7%9C%8B-etcd-%E9%9B%86%E7%BE%A4%E7%9A%84%E8%8A%82%E7%82%B9" title="查看 etcd 集群的节点"></a>查看 etcd 集群的节点</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \ </span><br><span class="line">--cacert=/etc/kubernetes/pki/etcd/ca.crt \ </span><br><span class="line">--cert=/etc/kubernetes/pki/etcd/peer.crt \ </span><br><span class="line">--key=/etc/kubernetes/pki/etcd/peer.key \</span><br><span class="line">member list</span><br></pre></td></tr></table></figure>

<h1 id="停止所有节点上的-etcd！（注意是所有！！）"><a href="#停止所有节点上的-etcd！（注意是所有！！）" class="headerlink" title="停止所有节点上的 etcd！（注意是所有！！）"></a><a href="#%E5%81%9C%E6%AD%A2%E6%89%80%E6%9C%89%E8%8A%82%E7%82%B9%E4%B8%8A%E7%9A%84-etcd%EF%BC%81%EF%BC%88%E6%B3%A8%E6%84%8F%E6%98%AF%E6%89%80%E6%9C%89%EF%BC%81%EF%BC%81%EF%BC%89" title="停止所有节点上的 etcd！（注意是所有！！）"></a>停止所有节点上的 etcd！（注意是所有！！）</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 如果是 static pod，可以听过如下的命令进行 stop</span><br><span class="line">## 如果是 systemd 管理的，可以通过 systemctl stop etcd</span><br><span class="line">mv /etc/kubernetes/manifests/etcd.yaml /etc/kubernetes/</span><br></pre></td></tr></table></figure>

<h1 id="数据清理"><a href="#数据清理" class="headerlink" title="数据清理"></a><a href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E7%90%86" title="数据清理"></a>数据清理</h1><p>依次在每个节点上，移除 etcd 数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rm -rf /var/lib/etcd</span><br></pre></td></tr></table></figure>

<h1 id="数据恢复"><a href="#数据恢复" class="headerlink" title="数据恢复"></a><a href="#%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D" title="数据恢复"></a>数据恢复</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 依次在每个节点上，恢复 etcd 旧数据</span><br><span class="line">## 里面的 name，initial-advertise-peer-urls，initial-cluster=controlplane</span><br><span class="line">## 等参数，可以从 etcd pod 的 yaml 文件中获取到。</span><br><span class="line">ETCDCTL_API=3 etcdctl snapshot restore ./old.snapshot.db \</span><br><span class="line">--data-dir=/var/lib/etcd \</span><br><span class="line">--name=controlplane \</span><br><span class="line">--initial-advertise-peer-urls=https://172.17.0.18:2380 \</span><br><span class="line">--initial-cluster=controlplane=https://172.17.0.18:2380</span><br></pre></td></tr></table></figure>

<h1 id="恢复-etcd-服务"><a href="#恢复-etcd-服务" class="headerlink" title="恢复 etcd 服务"></a><a href="#%E6%81%A2%E5%A4%8D-etcd-%E6%9C%8D%E5%8A%A1" title="恢复 etcd 服务"></a>恢复 etcd 服务</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 依次在每个节点上，拉起 etcd 服务</span><br><span class="line">mv /etc/kubernetes/etcd.yaml /etc/kubernetes/manifests/</span><br><span class="line">systemctl restart kubelet</span><br></pre></td></tr></table></figure>

<p>上述这些备份，都需要手动运行命令行进行操作。如果你的 Etcd 集群是运行在 Kubernetes 集群中的，你可以通过以下的定时 Job (CronJob) 来帮你自动化、周期性（如下的 YAML 文件中会每分钟对 Etcd 进行一次备份）地备份 Etcd 的数据。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: batch/v1beta1</span><br><span class="line">kind: CronJob</span><br><span class="line">metadata:</span><br><span class="line">  name: backup</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  # activeDeadlineSeconds: 100</span><br><span class="line">  schedule: &quot;*/1 * * * *&quot;</span><br><span class="line">  jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        spec:</span><br><span class="line">          containers:</span><br><span class="line">          - name: backup</span><br><span class="line">            image: k8s.gcr.io/etcd:3.2.24</span><br><span class="line">            env:</span><br><span class="line">            - name: ETCDCTL_API</span><br><span class="line">              value: &quot;3&quot;</span><br><span class="line">            command: [&quot;/bin/sh&quot;]</span><br><span class="line">            args: [&quot;-c&quot;, &quot;etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt --key=/etc/kubernetes/pki/etcd/healthcheck-client.key snapshot save /backup/etcd-snapshot-$(date +%Y-%m-%d_%H:%M:%S_%Z).db&quot;]</span><br><span class="line">            volumeMounts:</span><br><span class="line">            - mountPath: /etc/kubernetes/pki/etcd</span><br><span class="line">              name: etcd-certs</span><br><span class="line">              readOnly: true</span><br><span class="line">            - mountPath: /backup</span><br><span class="line">              name: backup</span><br><span class="line">          restartPolicy: OnFailure</span><br><span class="line">          hostNetwork: true</span><br><span class="line">          volumes:</span><br><span class="line">          - name: etcd-certs</span><br><span class="line">            hostPath:</span><br><span class="line">              path: /etc/kubernetes/pki/etcd</span><br><span class="line">              type: DirectoryOrCreate</span><br><span class="line">          - name: backup</span><br><span class="line">            hostPath:</span><br><span class="line">              path: /data/backup</span><br><span class="line">              type: DirectoryOrCreate</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kubernetes</category>
        <category>etcd</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Dokcer 部署RabbitMQ集群-镜像模式（实战）</title>
    <url>/2021/03/01/datebases/rabbitmq-mirror/</url>
    <content><![CDATA[<h1 id="RabbitMQ简介"><a href="#RabbitMQ简介" class="headerlink" title="RabbitMQ简介"></a>RabbitMQ简介</h1><p>RabbitMQ是一个开源的消息中间件，它实现了高级消息队列协议(AMQP)，支持多种语言，如Java、Python、Ruby、PHP、C#、JavaScript等。</p>
<span id="more"></span>

<hr>
<p>RabbitMQ部署模式大概分为以下三种:</p>
<ol>
<li>单一模式。</li>
<li>普通模式(默认的集群模式)。</li>
<li>镜像模式(把需要的队列做成镜像队列，存在于多个节点，属于RabbitMQ的HA方案，在对业务可靠性要求较高的场合中比较适用)。</li>
</ol>
<h1 id="RabbitMQ模式详解"><a href="#RabbitMQ模式详解" class="headerlink" title="RabbitMQ模式详解"></a>RabbitMQ模式详解</h1><p>abbitmq普通集群模式，是将交换机、绑定、队列的元数据复制到集群里的任何一个节点，但队列内容只存在于特定的节点中，客户端通过连接集群中任意一个节点，即可以生产和消费集群中的任何队列内容（因为每个节点都有集群中所有队列的元数据信息，如果队列内容不在本节点，则本节点会从远程节点获取内容，然后提供给消费者消费）。<br>从该模式不难看出，普通集群可以让不同的繁忙队列从属于不同的节点，这样可以减轻单节点的压力，提升吞吐量，但是普通集群不能保证队列的高可用性，因为一旦队列所在节点宕机直接导致该队列无法使用，只能等待重启，所以要想在队列节点宕机或故障也能正常使用，就要复制队列内容到集群里的每个节点，需要创建镜像队列。<br>rabbitmq镜像集群依赖于普通集群，所以需要先搭建rabbitmq普通集群。</p>
<h1 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h1><p>要实现镜像模式，需要先搭建一个普通集群模式，在这个模式的基础上再配置镜像模式以实现高可用，本次实践部署rabbitmq采用的版本（rabbitmq:3.8.7-management）。</p>
<h2 id="主机列表"><a href="#主机列表" class="headerlink" title="主机列表"></a>主机列表</h2><table>
<thead>
<tr>
<th>主机</th>
<th>节点模式</th>
</tr>
</thead>
<tbody><tr>
<td>192.168.1.32</td>
<td>磁盘节点</td>
</tr>
<tr>
<td>192.168.1.33</td>
<td>内存节点</td>
</tr>
<tr>
<td>192.168.1.35</td>
<td>内存节点</td>
</tr>
</tbody></table>
<h1 id="部署RabbitMQ"><a href="#部署RabbitMQ" class="headerlink" title="部署RabbitMQ"></a>部署RabbitMQ</h1><h2 id="创建持久数据目录"><a href="#创建持久数据目录" class="headerlink" title="创建持久数据目录"></a>创建持久数据目录</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir /data/rabbitmq -p   //三台主机均执行</span><br></pre></td></tr></table></figure>
<h2 id="host配置-rabbitmq集群需要解析主机名"><a href="#host配置-rabbitmq集群需要解析主机名" class="headerlink" title="host配置(rabbitmq集群需要解析主机名)"></a>host配置(rabbitmq集群需要解析主机名)</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /data/rabbitmq</span><br><span class="line">vim hosts</span><br><span class="line"># hosts 内容</span><br><span class="line">192.168.1.32 rabbit1</span><br><span class="line">192.168.1.33 rabbit2</span><br><span class="line">192.168.1.35 rabbit3</span><br></pre></td></tr></table></figure>

<h2 id="创建容器"><a href="#创建容器" class="headerlink" title="创建容器"></a>创建容器</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --restart=always \</span><br><span class="line">  --net host \</span><br><span class="line">  --hostname rabbit1 \</span><br><span class="line">  --name rabbit1  \</span><br><span class="line">  -v /data/rabbitmq:/var/lib/rabbitmq \</span><br><span class="line">  -v /data/rabbitmq/hosts:/etc/hosts \</span><br><span class="line">  -e RABBITMQ_ERLANG_COOKIE=&#x27;secret cookie here&#x27; \</span><br><span class="line">  rabbitmq:3.8.7-management</span><br><span class="line">  </span><br><span class="line">  docker run -d --restart=always \</span><br><span class="line">  --net host \</span><br><span class="line">  --hostname rabbit2 \</span><br><span class="line">  --name rabbit2  \</span><br><span class="line">  -v /data/rabbitmq:/var/lib/rabbitmq \</span><br><span class="line">  -v /data/rabbitmq/hosts:/etc/hosts \</span><br><span class="line">  -e RABBITMQ_ERLANG_COOKIE=&#x27;secret cookie here&#x27; \</span><br><span class="line">  rabbitmq:3.8.7-management</span><br><span class="line">  </span><br><span class="line">  docker run -d --restart=always \</span><br><span class="line">  --net host \</span><br><span class="line">  --hostname rabbit3 \</span><br><span class="line">  --name rabbit3  \</span><br><span class="line">  -v /data/rabbitmq:/var/lib/rabbitmq \</span><br><span class="line">  -v /data/rabbitmq/hosts:/etc/hosts \</span><br><span class="line">  -e RABBITMQ_ERLANG_COOKIE=&#x27;secret cookie here&#x27; \</span><br><span class="line">  rabbitmq:3.8.7-management</span><br><span class="line"></span><br><span class="line">注意：hostname 不要重复</span><br></pre></td></tr></table></figure>

<h3 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-d</span><br><span class="line">#容器后台运行</span><br><span class="line">--restart=always</span><br><span class="line"># 容器重启策略, always 在容器退出时总是重启容器</span><br><span class="line">--net host</span><br><span class="line">#容器和宿主机共用网络(注意端口冲突)</span><br><span class="line">--hostname rabbit1</span><br><span class="line">#容器的主机名为 rabbit1，容器内部的hostname</span><br><span class="line">--name rabbit1</span><br><span class="line">#容器名为rabbit1，在宿主机上运行“docker ps”命令时显示的名称</span><br><span class="line">-v /data/rabbitmq:/var/lib/rabbitmq</span><br><span class="line">#将宿主机目录/data/rabbitmq挂载到容器的/var/lib/rabbitmq目录</span><br><span class="line">-v /data/rabbitmq/hosts:/etc/hosts</span><br><span class="line">#将宿主机目录/data/rabbitmq/hosts文件挂载到容器的/etc/hosts文件</span><br><span class="line">-e RABBITMQ_DEFAULT_USER=user01</span><br><span class="line">#设置rabbitmq默认用户为user01</span><br><span class="line">-e RABBITMQ_DEFAULT_PASS=password01</span><br><span class="line">#设置rabbitmq默认密码为password01</span><br><span class="line">-e RABBITMQ_ERLANG_COOKIE=&#x27;secret cookie&#x27;</span><br><span class="line">#设置rabbitmq的cookie为“secret cookie”，可以自定义为其他文本，三个容器保持一致即可。</span><br><span class="line">rabbitmq:3.8.7-management</span><br><span class="line">#使用rabbitmq:3.8.7-management这个镜像</span><br></pre></td></tr></table></figure>

<p><em><strong>三台机器都执行上面的命令,hostname和容器name需要修改</strong></em></p>
<h2 id="将节点2-3加入集群"><a href="#将节点2-3加入集群" class="headerlink" title="将节点2,3加入集群"></a>将节点2,3加入集群</h2><p>在rabbit2机器进入容器的命令行</p>
<pre><code>docker exec -it rabbit2 /bin/bash
加入集群
rabbitmqctl stop_app
rabbitmqctl join_cluster rabbit@rabbit1
rabbitmqctl join_cluster rabbit@rabbit1 --ram  //表示该节点为内存节点，默认为磁盘节点。
rabbitmqctl start_app
rabbit3执行相同的命令

查询集群状态
rabbitmqctl cluster_status
</code></pre>
<h3 id="特别说明："><a href="#特别说明：" class="headerlink" title="特别说明："></a>特别说明：</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在上述部署已完成的情况下更改节点模式(硬盘模式-disc、内存模式-ram)</span><br><span class="line"># 更改节点: rabbit@rabbit2为硬盘模式,操作如下：</span><br><span class="line"># 进入任意容器内</span><br><span class="line">rabbitmqctl -n rabbit@rabbit2 stop_app</span><br><span class="line">rabbitmqctl -n rabbit@rabbit2 change_cluster_node_type disc</span><br><span class="line">rabbitmqctl -n rabbit@rabbit2 start_app</span><br></pre></td></tr></table></figure>

<h2 id="配置镜像集群策略"><a href="#配置镜像集群策略" class="headerlink" title="配置镜像集群策略"></a>配置镜像集群策略</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">新添加用户</span><br><span class="line">rabbitmqctl list_users     //查看用户列表</span><br><span class="line">rabbitmqctl add_user admin 123456   //新增用户、密码</span><br><span class="line">rabbitmqctl set_user_tags admin administrator  // 设置admin用户标记，administrator表示最高权限</span><br><span class="line">rabbitmqctl set_permissions -p &quot;/&quot; admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;   //设置权限</span><br></pre></td></tr></table></figure>

<h3 id="开启镜像集群模式"><a href="#开启镜像集群模式" class="headerlink" title="开启镜像集群模式"></a>开启镜像集群模式</h3><p>搭建镜像集群是在web控制台完成的，主要操作就是在Admin界面添加一个Policy<br>添加策略：登录rabbitmq管理页面 ——&gt; Admin ——&gt; Policies ——&gt; Add &#x2F; update a policy，填写对应的镜像策略。<br><img src="/images/article_image/rabbitmq_mirror_1.png" alt="Alt"><br><img src="/images/article_image/rabbitmq_mirror_2.png" alt="Alt"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Policy参数含义</span><br><span class="line">pattern: 队列名字的通配符 或者 ^ 匹配符，只有一个^代表匹配所有</span><br><span class="line">ha-mode：镜像队列提供了三种模式：</span><br><span class="line">        all：全部的节点队列都做镜像；</span><br><span class="line">        exactly：指定镜像队列的节点最高镜像数量；</span><br><span class="line">        nodes：只为指定具体节点配置镜像队列；</span><br><span class="line">ha-sync-mode ：节点之前的同步模式。有自动和手动两种，默认是手动，这里设置为自动。</span><br></pre></td></tr></table></figure>

<p>设置完成并添加了这个策略后，新建的和已存在的队列默认会支持此策略。</p>
<p>出现如下图所示，表示配置完成<br><img src="/images/article_image/rabbitmq_mirror_3.png" alt="Alt"><br><em><strong>到此，镜像集群部署工作完成。</strong></em></p>
<h1 id="RabbitMQ监控"><a href="#RabbitMQ监控" class="headerlink" title="RabbitMQ监控"></a>RabbitMQ监控</h1><p>使用两种流行的工具介绍RabbitMQ监视： Prometheus，一个监视工具包；和Grafana，一个度量可视化系统。<br>从3.8.0版开始，RabbitMQ附带了内置的Prometheus＆Grafana支持。<br>Rabbitmq_prometheus插件随附了对Prometheus度量标准收集器的支持。该插件以Prometheus文本格式在专用TCP端口上公开所有RabbitMQ指标。<br>这些度量标准提供了对RabbitMQ节点状态和运行时的深入了解。他们使有关RabbitMQ的行为，使用它的应用程序以及各种基础结构元素的推理变得更加明智。</p>
<h2 id="启用rabbitmq-prometheus"><a href="#启用rabbitmq-prometheus" class="headerlink" title="启用rabbitmq_prometheus"></a>启用rabbitmq_prometheus</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">在所有节点上启用rabbitmq_prometheus 插件</span><br><span class="line">rabbitmq-plugins enable rabbitmq_prometheus</span><br></pre></td></tr></table></figure>

<p>获取指标，如下所示有监控指标出现，即表示监控插件开启</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl -s localhost:15692/metrics | head -n 3</span><br><span class="line"># TYPE erlang_mnesia_held_locks gauge</span><br><span class="line"># HELP erlang_mnesia_held_locks Number of held locks.</span><br><span class="line">erlang_mnesia_held_locks 0</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>数据库</category>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title>本地部署Ollama+DeepSeek-R1</title>
    <url>/2025/03/17/deepseek/ollama_deepseek_deployment/</url>
    <content><![CDATA[<h1 id="什么是-Ollama-？"><a href="#什么是-Ollama-？" class="headerlink" title="什么是 Ollama ？"></a>什么是 Ollama ？</h1><p>Ollama是一个专为在本地机器上便捷部署和运行大型语言模型（LLM）而设计的开源框架，它可以用简单的命令行快捷部署多种大模型，例如 DeepSeek、Qwen、Llama3 等等模型。</p>
<span id="more"></span>
<hr>
<p>Ollama 有一个非常出色的特性，这也是众多开发者选择它的关键原因，即 Ollama 为所有支持的模型封装了统一的 API，并且兼容 OpenAI 数据格式。这一点至关重要，由于模型是由不同公司或团队训练的，每种模型原本都提供各自的开发接口。因此，Ollama进行统一封装后，用户在使用时就变得极为便。</p>
<p>比如，我们编写 Agent 代码时，就会把标准的 OpenAI SDK 的 base_url 参数和模型名称做出修改。同样地，如果通过 Ollama 访问 DeepSeek，只需将 base_url 修改为 Ollama 的地址即可。后期如果需要切换到 Qwen 模型，也无需再修改 base_url，只需更换模型名称即可。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">client = OpenAI( api_key=os.getenv(&quot;AliDeep&quot;),</span><br><span class="line">base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;)</span><br></pre></td></tr></table></figure>

<h1 id="Ollama部署DeepSeek-R1"><a href="#Ollama部署DeepSeek-R1" class="headerlink" title="Ollama部署DeepSeek-R1"></a>Ollama部署DeepSeek-R1</h1><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>操作系统：Ubuntu 22.04，显卡：T4（16G显存）<br>使用 nvidia-smi 命令，确认 GPU 卡的驱动已经装好，可以被识别。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@lptest001:~# nvidia-smi                                                                                                                                                </span><br><span class="line">Mon Mar 17 12:14:48 2025                                                                                                                                                 </span><br><span class="line">+-----------------------------------------------------------------------------+                                                                                          </span><br><span class="line">| NVIDIA-SMI 515.76       Driver Version: 515.76       CUDA Version: 11.7     |                                                                                          </span><br><span class="line">|-------------------------------+----------------------+----------------------+                                                                                          </span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |                                                                                          </span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |                                                                                          </span><br><span class="line">|                               |                      |               MIG M. |                                                                                          </span><br><span class="line">|===============================+======================+======================|                                                                                          </span><br><span class="line">|   0  Tesla T4            Off  | 00000000:00:07.0 Off |                    0 |                                                                                          </span><br><span class="line">| N/A   42C    P0    25W /  70W |      2MiB / 15360MiB |      0%      Default |                                                                                          </span><br><span class="line">|                               |                      |                  N/A |                                                                                          </span><br><span class="line">+-------------------------------+----------------------+----------------------+                                                                                                                                                                                    </span><br><span class="line">                                                                                                                                                                         </span><br><span class="line">+-----------------------------------------------------------------------------+                                                                                          </span><br><span class="line">| Processes:                                                                  |                                                                                          </span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |                                                                                          </span><br><span class="line">|        ID   ID                                                   Usage      |                                                                                          </span><br><span class="line">|=============================================================================|                                                                                          </span><br><span class="line">|  No running processes found                                                 |                                                                                          </span><br><span class="line">+-----------------------------------------------------------------------------+ </span><br></pre></td></tr></table></figure>

<h2 id="安装-Ollama"><a href="#安装-Ollama" class="headerlink" title="安装 Ollama"></a>安装 Ollama</h2><p>官方推荐的 Docker 方式部署 Ollama，便于进行版本的管理与测试。<br>首先将 Ollama 镜像下载到本地，由于国内无法访问DockerHub，因此大家可以使用后面命令中的代理地址访问：</p>
<pre><code>docker pull docker.1ms.run/ollama/ollama:0.5.11
</code></pre>
<p>之后使用命令启动 Ollama 容器：</p>
<pre><code>docker run -dp 8880:11434 --gpus device=0 --name DeepSeek-R1-1 docker.1ms.run/ollama/ollama:0.5.11
</code></pre>
<p><em><strong>命令详解：</strong></em><br>-d 表示以守护进程方式运行容器,后台运行。<br>-p 8880:11434 将容器的11434端口映射到宿主机的8880端口，11434为Ollama默认提供API访问的端口。<br>–gpus device&#x3D;0 表示该容器使用GPU 0号卡，通过前面执行nvidia-smi命令时知道的。<br>–name DeepSeek-R1-1 给容器起一个名字 最后是容器镜像的名称。</p>
<p>执行创建容器命令之后，可以通过docker ps命令查询到容器的信息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@lptest001:~# docker ps         </span><br><span class="line">CONTAINER ID   IMAGE                                 COMMAND               CREATED          STATUS         PORTS                                           NAMES         </span><br><span class="line">7049f65fd9d3   docker.1ms.run/ollama/ollama:0.5.11   &quot;/bin/ollama serve&quot;   10 seconds ago   Up 9 seconds   0.0.0.0:8880-&gt;11434/tcp, [::]:8880-&gt;11434/tcp   DeepSeek-R1-1</span><br></pre></td></tr></table></figure>

<p>创建ollama容器，经常会报如下的错误：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@lptest001:~# docker run -dp 8880:11434 --gpus device=0 --name DeepSeek-R1-1 docker.1ms.run/ollama/ollama:0.5.11</span><br><span class="line">7049f65fd9d3a539aa7660eb664caa585dba188720f0975701b73d87263b6cdf                                                                                                  </span><br><span class="line">docker: Error response from daemon: could not select device driver &quot;&quot; with capabilities: [[gpu]]. </span><br></pre></td></tr></table></figure>
<p>这是因为服务器的 NVIDIA Container Toolkit 没有装，需要执行如下命令安装一下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">distribution=$(. /etc/os-release;echo $ID$VERSION_ID)</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br><span class="line">apt-get update</span><br><span class="line">apt-get install -y nvidia-docker2</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>

<p>安装完成后，执行 docker info 命令，确保 docker 守护进程已经正确配置 GPU 支持。命令和输出如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@lptest001:~# docker info | grep -i nvidia                                                                                                                              </span><br><span class="line"> Runtimes: io.containerd.runc.v2 nvidia runc</span><br></pre></td></tr></table></figure>

<p>此时再重新 docker run，就可以将 Ollama 容器拉起了。</p>
<h2 id="部署与测试-DeepSeek-R1"><a href="#部署与测试-DeepSeek-R1" class="headerlink" title="部署与测试 DeepSeek-R1"></a>部署与测试 DeepSeek-R1</h2><p>Ollama 官方提供了一个可视化的模型仓库，便于我们了解 Ollama 已经支持了哪些模型，以及下载模型。仓库的地址是：<a href="https://ollama.com/library">https://ollama.com/library</a><br>点开链接后，找到 DeepSeek-R1 模型，共分为 1.5b 到 671b 多个版本。<br><img src="/images/article_image/deepseek_Deployment_2.png" alt="Alt"></p>
<p>点进去之后可以选择模型版本以及看到模型运行命令，更新记录等。</p>
<h3 id="两种-Ollama-拉起-DeepSeek-R1-的方案"><a href="#两种-Ollama-拉起-DeepSeek-R1-的方案" class="headerlink" title="两种 Ollama 拉起 DeepSeek-R1 的方案"></a>两种 Ollama 拉起 DeepSeek-R1 的方案</h3><h4 id="在容器内下载模型和拉起"><a href="#在容器内下载模型和拉起" class="headerlink" title="在容器内下载模型和拉起"></a>在容器内下载模型和拉起</h4><p>我们需要进入到 Ollama 容器的内部，去执行模型运行命令。进入容器的命令为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it &lt;你的容器名称或 ID&gt; /bin/bash</span><br></pre></td></tr></table></figure>
<p>然后执行模型运行命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ollama run deepseek-r1:32b</span><br></pre></td></tr></table></figure>
<p>输出如下，由于本地没有模型，所以，会先在模型仓库下载模型，我们需要耐心等待模型下载完毕。<br><img src="/images/article_image/deepseek_Deployment_3.png" alt="Alt"><br>下载完成后，就会加载模型，直到出现 success，模型就加载好了。<br><img src="/images/article_image/deepseek_Deployment_4.png" alt="Alt"><br>直接输入对话，测试效果。例如：<br><img src="/images/article_image/deepseek_Deployment_5.png" alt="Alt"><br>可以看到，模型带有 DeepSeek-R1 标志性的 <think></think> 也就是深度思考，但是由于我们问的问题太简单了，模型认为不需要深度思考就能回答，因此就直接回答了。</p>
<h4 id="将模型文件挂载进容器（推荐）"><a href="#将模型文件挂载进容器（推荐）" class="headerlink" title="将模型文件挂载进容器（推荐）"></a>将模型文件挂载进容器（推荐）</h4><p>高可用部署需要至少起两个 Ollama容器，因此用这种方式只下载一次模型文件就可以，比较方便。</p>
<p>执行如下命令，在服务器上安装 Ollama 工具。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></table></figure>
<p>之后直接将模型下载到本地：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ollama pull deepseek-r1:32b</span><br></pre></td></tr></table></figure>
<p>启动容器，将模型挂载进去，需要注意 Ollama 在 ubuntu 服务器上的默认是模型文件存放目录 &#x2F;usr&#x2F;share&#x2F;ollama&#x2F;.ollama&#x2F;models，但是在容器中的目录是 &#x2F;root&#x2F;.ollama&#x2F;models，挂载时要写成服务器目录: 容器目录的格式，注意不要写反了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -dp 8880:11434 --runtime=nvidia --gpus device=0 --name DeepSeek-R1-1 -v /usr/share/ollama/.ollama/models:/root/.ollama/models docker.1ms.run/ollama/ollama:0.5.11</span><br></pre></td></tr></table></figure>
<p>最后查看容器中的模型是否已经运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@lptest001:~# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9a44f04e78f7 docker.1ms.run/ollama/ollama:0.5.11 &quot;/bin/ollama serve&quot; 6 minutes ago Up 6 minutes 0.0.0.0:8880-&gt;11434/tcp,</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>DeepSeek</category>
      </categories>
      <tags>
        <tag>Ollama</tag>
        <tag>Deepseek</tag>
      </tags>
  </entry>
  <entry>
    <title>Log-pilot日志采集收集java堆栈异常日志</title>
    <url>/2020/05/22/log_dataesource/Log-pilot/</url>
    <content><![CDATA[<p>微服务应用发展迅速，建立一套集中式日志收集系统，将所有节点上的日志统一收集、管理、访问，将极大提高定位问题的效率。</p>
<span id="more"></span>
<hr>
<p>一、k8s集群日志收集方案<br>       在测试环境部署了log-polit+elk的方案；部署完成之后，日志系统收集java多行异常日志，存在kibana分行的现象，如下图所示:<br>       <img src="/images/article_image/log-pliot_1.png" alt="Alt"></p>
<p>二、配置Log-polit<br>1）经过多次的测试，Fliebeat需要更改配置才能处理跨多行日志。使用Log-pilot组件，采集插件支持Filebeat、Fluentd两种，Log-Pilot 能够自动感知宿主机上容器的创建删除事件，进而动态配置容器日志采集配置文件，因此Filebeat、Fluentd的采集配置是有固定模板，配置则需要在Log-poilt打包镜像前配置。<br> 2）本人使用的版本为：log-pilot:v0.9.7-filebeat， log-polit官方源码：<a href="https://github.com/AliyunContainerService/log-pilot.git">https://github.com/AliyunContainerService/log-pilot.git</a> ，通过git clone 下载到本地，在filebeat.tpl文件中添加红框中的的参数，如下图所示:<br> <img src="/images/article_image/log-pliot_2.png" alt="Alt"></p>
<pre><code> 参数详情：
</code></pre>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">multiline.pattern: &#x27;^\[&#x27;   	  // 匹配是将多行日志所有不是以[符号开头的行合并成一行</span><br><span class="line">multiline.negate: true		 //  是否需要对pattern条件转置使用，不翻转设为true，反转设置为false</span><br><span class="line">multiline.match: after 		//   匹配pattern后，与前面（before）还是后面（after）的内容合并为一条日志</span><br></pre></td></tr></table></figure>
<p>3）使用代码库的Dockerfile重新生成镜像、部署，kibana显示的日志合并为一行，如下图：<br><img src="/images/article_image/log-pliot_3.png" alt="Alt"></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>日志采集</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 命令（1）—— sed 命令</title>
    <url>/2021/03/03/linux_cmd/cmd_sed/</url>
    <content><![CDATA[<h1 id="命令简介"><a href="#命令简介" class="headerlink" title="命令简介"></a>命令简介</h1><p>sed（Stream EDitor）是一种流文件编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（Pattern Space），接着用 sed 命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕，接着处理下一行，直到文件末尾。文件内容并没有改变，除非使用-i选项。sed 主要用来编辑一个或多个文件，简化对文件的反复操作或者用来编写转换程序等。</p>
<p>sed 功能同 awk 类似，差别在于，sed 简单，对列处理的功能要差一些，awk 功能复杂，对列处理的功能比较强大。</p>
<span id="more"></span>

<hr>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">转载：https://blog.csdn.net/K346K346/article/details/53197905</span><br></pre></td></tr></table></figure>


<h1 id="命令格式"><a href="#命令格式" class="headerlink" title="命令格式"></a>命令格式</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sed [OPTION]... &#123;script-only-if-no-other-script&#125; [input-file]...</span><br></pre></td></tr></table></figure>

<p>其中 OPTION 为命令选项，script-only-if-no-other-script 为处理动作，可以由-e指定多个，input-file为输入文件，可指定多个。</p>
<h2 id="选项说明"><a href="#选项说明" class="headerlink" title="选项说明"></a>选项说明</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">选项：</span><br><span class="line">-n,--quiet,--silent：使用安静模式。sed的一般用法中，所有来自STDIN的数据一般都会被打印到终端上，如果加上-n后，则只有经过sed特殊处理的那一行才会被列出来。</span><br><span class="line">-e &lt;script&gt;,--expression=&lt;script&gt;：指定sed动作，可以由多个-e指定多个动作。</span><br><span class="line">-f &lt;script-file&gt;,--file=&lt;script-file&gt;：直接将sed的动作写在一个文件内，-f filename则可以运行filename 内的sed动作；</span><br><span class="line">-r,--regexp-extended：sed支持扩展正则表达式(默认是基础正则表达式)。</span><br><span class="line">-i ：直接修改读取的文件内容，而不是输出到终端。</span><br><span class="line">--help：显示帮助。</span><br><span class="line">--version：显示版本。</span><br><span class="line"></span><br><span class="line">动作说明：[n1[,n2]]function</span><br><span class="line">n1, n2 ：不见得会存在，一般代表“选择进行动作的行数”，举例来说，如果我的动作是需要在 10 到 20 行之间进行，则写作“10,20动作行为”。</span><br><span class="line"></span><br><span class="line">function：</span><br><span class="line">a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～</span><br><span class="line">c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！</span><br><span class="line">d ：删除，因为是删除啊，所以 d 后面通常不接任何内容；</span><br><span class="line">i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；</span><br><span class="line">p ：列印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～</span><br><span class="line">s ：替换，通常这个s的动作可以搭配正规表示法！例如 1,20s/old/new/g。</span><br></pre></td></tr></table></figure>

<h1 id="典型示例"><a href="#典型示例" class="headerlink" title="典型示例"></a>典型示例</h1><h2 id="删除行操作"><a href="#删除行操作" class="headerlink" title="删除行操作"></a>删除行操作</h2><p>（1）将 &#x2F;etc&#x2F;passwd 的内容列出并且列印行号，同时，请将第 2~5 行删除。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[b3335@MIC ~]$ nl -n ln /etc/passwd | sed &#x27;2,5d&#x27;</span><br><span class="line">1 root:x:0:0:root:/root:/bin/bash</span><br><span class="line">6 sync:x:5:0:sync:/sbin:/bin/sync</span><br><span class="line">7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown</span><br><span class="line">.....(后面省略).....</span><br></pre></td></tr></table></figure>

<p>注意：原本应该是要下达 sed -e 才对，当只有一个动作的时候，没有 -e 也行，但是多于一个动作时必须要使用-e选项来指定动作。同时也要注意的是， sed 后面接的动作，请务必以两个单引号括住。</p>
<p>（2）只要删除第 2 行。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nl /etc/passwd | sed &#x27;2d&#x27; </span><br></pre></td></tr></table></figure>

<p>（3）要删除第 3 到最后一行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nl /etc/passwd | sed &#x27;3,$d&#x27; </span><br></pre></td></tr></table></figure>

<h2 id="新增行操作"><a href="#新增行操作" class="headerlink" title="新增行操作"></a>新增行操作</h2><p>（1）在第二行后加上”I like drinking tea”。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[b3335@MIC ~]$ nl -n ln /etc/passwd | sed &#x27;2a I like drinking tea&#x27;</span><br><span class="line">1    root:x:0:0:root:/root:/bin/bash</span><br><span class="line">2    bin:x:1:1:bin:/bin:/sbin/nologin</span><br><span class="line">I like drinking tea</span><br><span class="line">3    daemon:x:2:2:daemon:/sbin:/sbin/nologin</span><br><span class="line">.....(后面省略).....</span><br></pre></td></tr></table></figure>

<p>（2）那如果是要在第二行前加入。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nl /etc/passwd | sed &#x27;2i drink tea&#x27;</span><br><span class="line">//或</span><br><span class="line">nl /etc/passwd | sed &#x27;1a drink tea&#x27;</span><br></pre></td></tr></table></figure>

<p>（3）在第二行后面加入两行，“I like drinking tea”与”I like drinking beer”。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[b3335@MIC ~]$ nl -n ln /etc/passwd | sed &#x27;2a I like drinking tea\nI like drinking beer&#x27;</span><br><span class="line">1         root:x:0:0:root:/root:/bin/bash</span><br><span class="line">2         bin:x:1:1:bin:/bin:/sbin/nologin</span><br><span class="line">I like drinking tea</span><br><span class="line">I like drinking beer</span><br><span class="line">3         daemon:x:2:2:daemon:/sbin:/sbin/nologin</span><br><span class="line">…（后面省略）…</span><br></pre></td></tr></table></figure>

<p>或者每一行使用反斜杠\来分开，就可以在命令行中将一条命令分开多行输入，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[b3335@MIC ~]$ nl -n ln /etc/passwd | sed &#x27;2a I like drinking tea\</span><br><span class="line">&gt; I like drinking beer&#x27;</span><br></pre></td></tr></table></figure>

<h2 id="替换行操作"><a href="#替换行操作" class="headerlink" title="替换行操作"></a>替换行操作</h2><p>（1）将第2-5行的内容替换成为”No 2-5 number”。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[b3335@MIC ~]$ nl -nln /etc/passwd | sed &#x27;2,5c No 2-5 number&#x27;</span><br><span class="line">1         root:x:0:0:root:/root:/bin/bash</span><br><span class="line">No 2-5 number</span><br><span class="line">6         sync:x:5:0:sync:/sbin:/bin/sync</span><br><span class="line">.....(后面省略).....</span><br></pre></td></tr></table></figure>

<h2 id="选择行打印"><a href="#选择行打印" class="headerlink" title="选择行打印"></a>选择行打印</h2><p>（1）仅列出 &#x2F;etc&#x2F;passwd 文件内的第 5-7 行。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@www ~]# nl -nln /etc/passwd | sed -n &#x27;5,7p&#x27;</span><br><span class="line">5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin</span><br><span class="line">6 sync:x:5:0:sync:/sbin:/bin/sync</span><br><span class="line">7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown</span><br></pre></td></tr></table></figure>

<h2 id="数据的查找并进行相关操作"><a href="#数据的查找并进行相关操作" class="headerlink" title="数据的查找并进行相关操作"></a>数据的查找并进行相关操作</h2><p>（1）数据的查找并显示<br>搜索 &#x2F;etc&#x2F;passwd有root关键字的行并输出。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[b3335@MIC ~]$ nl /etc/passwd | sed -n &#x27;/root/p&#x27;</span><br><span class="line">1    root:x:0:0:root:/root:/bin/bash</span><br><span class="line">11    operator:x:11:0:operator:/root:/sbin/nologin</span><br></pre></td></tr></table></figure>

<p>（2）数据的查找并删除<br>删除&#x2F;etc&#x2F;passwd所有包含root的行，其他行输出。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[b3335@MIC ~]$ nl /etc/passwd | sed  &#x27;/root/d&#x27;</span><br><span class="line">2  daemon:x:1:1:daemon:/usr/sbin:/bin/sh</span><br><span class="line">3  bin:x:2:2:bin:/bin:/bin/sh</span><br><span class="line">…（下面忽略）…</span><br></pre></td></tr></table></figure>

<p>如果想删除匹配的字符串，使用如下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[b3335@MIC ~]$ nl /etc/passwd | sed  &#x27;s/root//g&#x27;</span><br></pre></td></tr></table></figure>

<p>（3）数据的查找并替换<br>除了整行的处理模式之外， sed 还可以用行为单位进行部分数据的搜寻并取代。基本上 sed 的搜寻与替代的与 vi 相当的类似！他有点像这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sed &#x27;s/被取代的字串/新的字串/g&#x27;</span><br></pre></td></tr></table></figure>

<p>（4）数据的搜寻并执行命令<br>搜索&#x2F;etc&#x2F;passwd,找到root对应的行，执行后面花括号中的一组命令，每个命令之间用分号分隔，这里把bash替换为blueshell，再输出这行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nl /etc/passwd | sed -n &#x27;/root/&#123;s/bash/blueshell/;p&#125;&#x27;</span><br><span class="line">1  root:x:0:0:root:/root:/bin/blueshell</span><br></pre></td></tr></table></figure>

<p>如果只替换&#x2F;etc&#x2F;passwd的第一个bash关键字为blueshell，就退出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nl /etc/passwd | sed -n &#x27;/bash/&#123;s/bash/blueshell/;p;q&#125;&#x27;    </span><br><span class="line">1  root:x:0:0:root:/root:/bin/blueshell</span><br></pre></td></tr></table></figure>

<h2 id="多点编辑"><a href="#多点编辑" class="headerlink" title="多点编辑"></a>多点编辑</h2><p>一条sed命令，删除&#x2F;etc&#x2F;passwd第三行到末尾的数据，并把bash替换为blueshell</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nl /etc/passwd | sed -e &#x27;3,$d&#x27; -e &#x27;s/bash/blueshell/&#x27;</span><br><span class="line">1  root:x:0:0:root:/root:/bin/blueshell</span><br><span class="line">2  daemon:x:1:1:daemon:/usr/sbin:/bin/sh</span><br></pre></td></tr></table></figure>

<p>-e表示多点编辑，第一个编辑命令删除&#x2F;etc&#x2F;passwd第三行到末尾的数据，第二条命令搜索bash替换为blueshell。</p>
<h2 id="直接修改文件"><a href="#直接修改文件" class="headerlink" title="直接修改文件"></a>直接修改文件</h2><p>sed 可以直接修改文件的内容，不必使用管道命令或数据流重导向！ 不过，由於这个动作会直接修改到原始的文件，所以请你千万不要随便拿系统配置来测试，使用时也要慎重。我们使用下载的regular_express.txt 文件来测试看看吧！</p>
<p>利用 sed 将 regular_express.txt 内每一行结尾若为 . 则换成 !</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@www ~]# sed -i &#x27;s/\.$/!/g&#x27; regular_express.txt</span><br></pre></td></tr></table></figure>

<p>利用 sed 直接在 regular_express.txt 最后一行加入”# This is a test”。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@www ~]# sed -i &#x27;$a # This is a test&#x27; regular_express.txt</span><br></pre></td></tr></table></figure>

<p>由於 $ 代表的是最后一行，而 a 的动作是新增，因此该文件最后新增”# This is a test”。</p>
<p>sed 的-i选项可以直接修改文件内容，这功能非常有帮助！举例来说，如果你有一个 100 万行的文件，你要在第 100 行加某些文字，此时使用 vim 可能会疯掉！因为文件太大了！那怎办？就利用 sed 啊！透过 sed 直接修改&#x2F;取代的功能，你甚至不需要使用 vim 去修订！</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] Linux sed命令详解<br>[2] 鸟哥.鸟哥的私房菜基础学习篇第三版[M].北京：人民邮电出版社，2010：357-360</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>常用命令</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 命令（2）—— xargs 命令</title>
    <url>/2021/03/03/linux_cmd/cmd_xargs/</url>
    <content><![CDATA[<h1 id="命令简介"><a href="#命令简介" class="headerlink" title="命令简介"></a>命令简介</h1><p>xargs 可以将 stdin 中以空格或换行符进行分隔的数据，形成以空格分隔的参数（arguments），传递给其他命令。因为以空格作为分隔符，所以有一些文件名或者其他意义的字符串内含有空格的时候，xargs 可能会误判。简单来说，xargs 的作用是给其他命令传递参数，是构建单行命令的重要组件之一。</p>
<span id="more"></span>

<hr>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">转自：https://dablelv.blog.csdn.net/article/details/77151267</span><br></pre></td></tr></table></figure>



<p>之所以要用到 xargs，是因为很多命令不支持使用管道 | 来传递参数，例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find /sbin -perm +700 | ls -l         # 这个命令是错误,因为标准输入不能作为ls的参数</span><br><span class="line">find /sbin -perm +700 | xargs ls -l   # 这样才是正确的</span><br></pre></td></tr></table></figure>

<h1 id="命令格式"><a href="#命令格式" class="headerlink" title="命令格式"></a>命令格式</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xargs [OPTIONS] [COMMAND]</span><br></pre></td></tr></table></figure>

<h2 id="选项说明"><a href="#选项说明" class="headerlink" title="选项说明"></a>选项说明</h2><p>注意，长选项的强制性参数对于短选项也是强制的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-0, --null</span><br><span class="line">	如果输入的 stdin 含有特殊字符，例如反引号 `、反斜杠 \、空格等字符时，xargs 将它还原成一般字符。为默认选项</span><br><span class="line">-a, --arg-file=FILE</span><br><span class="line">	从指定的文件 FILE 中读取输入内容而不是从标准输入</span><br><span class="line">-d, --delimiter=DEL</span><br><span class="line">	指定 xargs 处理输入内容时的分隔符。xargs 处理输入内容默认是按空格和换行符作为分隔符，输出 arguments 时按空格分隔</span><br><span class="line">-E EOF_STR</span><br><span class="line">	EOF_STR 是 end of file string，表示输入的结束</span><br><span class="line">-e, --eof[=EOF_STR]</span><br><span class="line">	作用等同于 -E 选项，与 -E 选项不同时，该选项不符合 POSIX 标准且 EOF_STR 不是强制的。如果没有 EOF_STR 则表示输入没有结束符</span><br><span class="line">-I REPLACE_STR</span><br><span class="line">	将 xargs 输出的每一项参数单独赋值给后面的命令，参数需要用指定的替代字符串 REPLACE_STR 代替。REPLACE_STR 可以使用 &#123;&#125; $ @ 等符号，其主要作用是当 xargs command 后有多个参数时，调整参数位置。例如备份以 txt 为后缀的文件：find . -name &quot;*.txt&quot; | xargs -I &#123;&#125;  cp &#123;&#125; /tmp/&#123;&#125;.bak</span><br><span class="line">-i, --replace[=REPLACE_STR]</span><br><span class="line">	作用同 -I 选项，参数 REPLACE_STR 是可选的，缺省为 &#123;&#125;。建议使用 -I 选项，因为其符合 POSIX</span><br><span class="line">-L MAX_LINES</span><br><span class="line">	限定最大输入行数。隐含了 -x 选项</span><br><span class="line">-l, --max-lines[=MAX_LINES]</span><br><span class="line">	作用同 -L 选项，参数 MAX_LINES 是可选的，缺省为 1。建议使用 -L 选项，因为其符合 POSIX 标准</span><br><span class="line">-n, --max-args=MAX_ARGS</span><br><span class="line">	表示命令在执行的时候一次使用参数的最大个数</span><br><span class="line">-o, --open-tty</span><br><span class="line">	在执行命令之前，在子进程中重新打开stdin作为/dev/TTY。如果您希望xargs运行交互式应用程序，这是非常有用的</span><br><span class="line">-P, --max-procs=MAX_PROCS</span><br><span class="line">	每次运行最大进程；缺省值为 1。如果 MAX_PROCS 为 0，xargs 将一次运行尽可能多的进程。一般和 -n 或 -L 选项一起使用</span><br><span class="line">-p, --interactive</span><br><span class="line">	当每次执行一个 argument 的时候询问一次用户</span><br><span class="line">--process-slot-var=NAME</span><br><span class="line">	将指定的环境变量设置为每个正在运行的子进程中的唯一值。一旦子进程退出，将重用该值。例如，这可以用于初始负荷分配方案</span><br><span class="line">-r, --no-run-if-empty</span><br><span class="line">	当 xargs 的输入为空的时候则停止 xargs，不用再去执行后面的命令了。为默认选项</span><br><span class="line">-s, --max-chars=MAX_CHARS</span><br><span class="line">	命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数，包括命令、空格和换行符。每个参数单独传入 xargs 后面的命令</span><br><span class="line">--show-limits</span><br><span class="line">	显示操作系统对命令行长度的限制</span><br><span class="line">-t， --verbose</span><br><span class="line">	先打印命令到标准错误输出，然后再执行</span><br><span class="line">-x, --exit</span><br><span class="line">	配合 -s 使用，当命令行字符数大于 -s 指定的数值时，退出 xargs</span><br><span class="line">--help</span><br><span class="line">	显示帮助信息并退出</span><br><span class="line">--version</span><br><span class="line">	显示版本信息并退出</span><br></pre></td></tr></table></figure>

<h1 id="常用示例"><a href="#常用示例" class="headerlink" title="常用示例"></a>常用示例</h1><p>（1）将 Shell 的特殊字符反引号还原为一般字符。</p>
<pre><code>echo &#39;`0123`4 56789&#39; | xargs -t echo
echo `0123`4 56789 
`0123`4 56789
</code></pre>
<p>如果直接进行如下操作，会报无法找到命令 01234 的错误，因为反引号在 Shell 中会将 01234 作为一个命令来执行，但是 01234 不是一个命令。-t 表示先打印命令，然后再执行。</p>
<pre><code>echo `01234` 56789
-bash: 01234: command not found
56789
</code></pre>
<p>（2）设置 xargs 读入参数时的结束标识，以逗号结束。这里要注意结束标志必须要是单独的字段，即以空格或者换行符分隔的字段。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo 01234 , 56789 | xargs -E &quot;,&quot;</span><br><span class="line">01234</span><br></pre></td></tr></table></figure>

<p>（3）使用 rm、mv 等命令同时操作多个文件时，有时会报 “argument list too long” 参数列表过长的错误，此时可以使用 xargs 来解决。xargs 将标准输入的字符串分隔后，作为参数传递给后面的命令。例如，给当前目录的所有文件添加后缀名。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ls | xargs -t -i mv &#123;&#125; &#123;&#125;.bak</span><br><span class="line"># 选择符合条件的文件</span><br><span class="line">ls | grep -E &quot;201701|201702|201703&quot; | xargs -I &#123;&#125; mv &#123;&#125; &#123;&#125;.bak</span><br></pre></td></tr></table></figure>

<p>（4）设置命令行的最大字符数。参数默认一个一个单独传入命令中执行。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo &quot;01234 56789&quot; | xargs -t -s 11</span><br><span class="line">echo 01234 </span><br><span class="line">01234</span><br><span class="line">echo 56789 </span><br><span class="line">56789</span><br></pre></td></tr></table></figure>

<p>（5）设置标准输入中每次多少行作为命令的参数，默认是将标准输入中所有行的归并到一行一次性传给命令执行。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo -e &quot;01234\n56789\n01234&quot; | xargs -t -L 2 echo</span><br><span class="line">echo 01234 56789 </span><br><span class="line">01234 56789</span><br><span class="line">echo 01234 </span><br><span class="line">01234</span><br></pre></td></tr></table></figure>

<p>（6）将文件内容以空格分隔合并为一行输出。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 列出文件内容</span><br><span class="line">cat test.txt</span><br><span class="line">a b c d e</span><br><span class="line">f g h i j </span><br><span class="line">k l m n o</span><br><span class="line"></span><br><span class="line"># 多行输入合并为一行输出</span><br><span class="line">cat test.txt | xargs</span><br><span class="line">a b c d e f g h i j k l m n o</span><br></pre></td></tr></table></figure>

<p>（7）与 ps、grep、awk 和 kill 结合，强制终止指定进程。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ps -ef | grep spp | awk ‘&#123;printf “%s “,$2&#125;’ | xargs kill -9</span><br><span class="line"></span><br><span class="line"># ps -ef|grep spp 用于查找包含 spp 的进程，awk ‘&#123;printf “%s “,$2,FNR&#125;将目标进程 ID 打印输出，xargs kill -9 则将目标进程 ID 作为参数传递给kill -9用于杀死进程。</span><br></pre></td></tr></table></figure>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] xargs(1) manual<br>[2] CSDN.Xargs用法详解<br>[3] CSDN.linux xargs详解</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>常用命令</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
